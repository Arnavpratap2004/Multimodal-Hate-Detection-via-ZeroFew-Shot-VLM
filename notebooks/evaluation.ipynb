{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multimodal Hate Detection via Zero/Few-Shot VLMs\n",
                "\n",
                "This notebook provides an interactive environment for evaluating memes using the hate detection pipeline.\n",
                "\n",
                "## Pipeline\n",
                "```\n",
                "Image ‚Üí VLM ‚Üí Image description + OCR ‚Üí LLM ‚Üí HATE/NON-HATE\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if needed\n",
                "# !pip install -r ../requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import asyncio\n",
                "from pathlib import Path\n",
                "from IPython.display import display, Image, Markdown\n",
                "\n",
                "# Add src to path\n",
                "sys.path.insert(0, str(Path.cwd().parent))\n",
                "\n",
                "from src.config import settings\n",
                "from src.pipeline import HateDetector\n",
                "from src.evaluation import MetricsCalculator, FailureModeAnalyzer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the detector\n",
                "detector = HateDetector()\n",
                "\n",
                "# Check health\n",
                "health = await detector.health_check()\n",
                "print(f\"VLM: {'‚úÖ' if health['vlm'] else '‚ùå'} | LLM: {'‚úÖ' if health['llm'] else '‚ùå'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Single Meme Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function to display results nicely\n",
                "def display_result(result, show_image=True):\n",
                "    if show_image and Path(result.image_path).exists():\n",
                "        display(Image(filename=result.image_path, width=400))\n",
                "    \n",
                "    if result.error:\n",
                "        print(f\"‚ùå Error: {result.error}\")\n",
                "        return\n",
                "    \n",
                "    print(\"\\nüì∏ VLM Analysis:\")\n",
                "    print(f\"   Visual: {result.vlm_output.visual_description[:200]}...\")\n",
                "    print(f\"   OCR: {result.vlm_output.ocr_text}\")\n",
                "    print(f\"   Meaning: {result.vlm_output.implicit_meaning[:200]}...\")\n",
                "    print(f\"   Target: {result.vlm_output.target_group}\")\n",
                "    \n",
                "    label_emoji = \"üî¥\" if result.classification.label == \"HATE\" else \"üü¢\"\n",
                "    print(f\"\\n{label_emoji} Result: {result.classification.label}\")\n",
                "    print(f\"   Justification: {result.classification.justification}\")\n",
                "    print(f\"   Mode: {result.inference_mode} | Time: {result.processing_time:.2f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze a single meme\n",
                "image_path = \"../data/samples/your_meme.jpg\"  # Change this to your meme path\n",
                "\n",
                "# Choose mode: \"zero_shot\", \"few_shot\", or \"cot\"\n",
                "mode = \"zero_shot\"\n",
                "\n",
                "result = await detector.detect(image_path, mode)\n",
                "display_result(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare All Inference Modes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare all three modes on the same meme\n",
                "image_path = \"../data/samples/your_meme.jpg\"  # Change this\n",
                "\n",
                "results = await detector.compare_modes(image_path)\n",
                "\n",
                "print(\"Mode Comparison:\")\n",
                "print(\"-\" * 60)\n",
                "for mode, result in results.items():\n",
                "    label = result.classification.label\n",
                "    emoji = \"üî¥\" if label == \"HATE\" else \"üü¢\"\n",
                "    print(f\"{mode:12} | {emoji} {label:10} | {result.processing_time:.2f}s\")\n",
                "    print(f\"             | {result.classification.justification[:50]}...\")\n",
                "    print(\"-\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Batch Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate multiple memes\n",
                "meme_paths = [\n",
                "    \"../data/samples/meme1.jpg\",\n",
                "    \"../data/samples/meme2.jpg\",\n",
                "    \"../data/samples/meme3.jpg\",\n",
                "]\n",
                "\n",
                "batch_result = await detector.detect_batch(meme_paths, mode=\"zero_shot\")\n",
                "print(batch_result.accuracy_summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data.datasets import MultiBullyLoader, BanglaLoader\n",
                "\n",
                "# Load dataset\n",
                "dataset_path = \"../data/datasets/multibully\"\n",
                "loader = MultiBullyLoader(dataset_path)\n",
                "\n",
                "# Get statistics\n",
                "stats = loader.get_statistics()\n",
                "print(f\"Dataset: {loader.name}\")\n",
                "print(f\"Total samples: {stats['total_samples']}\")\n",
                "print(f\"HATE: {stats['hate_count']} | NON-HATE: {stats['non_hate_count']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run evaluation on subset\n",
                "samples = loader.get_samples(n=50, shuffle=True)\n",
                "\n",
                "calculator = MetricsCalculator()\n",
                "analyzer = FailureModeAnalyzer()\n",
                "\n",
                "for sample in samples:\n",
                "    result = await detector.detect(sample.image_path, \"zero_shot\")\n",
                "    \n",
                "    if not result.error:\n",
                "        calculator.add_result(result.classification.label, sample.ground_truth_label)\n",
                "        \n",
                "        if result.classification.label != sample.ground_truth_label:\n",
                "            analyzer.add_failure(result, sample.ground_truth_label)\n",
                "\n",
                "# Print results\n",
                "print(calculator.print_report())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze failures\n",
                "print(analyzer.generate_report())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Custom Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use code-mixed prompt mode for Hindi-English memes\n",
                "detector.set_vlm_prompt_mode(\"code_mixed\")\n",
                "\n",
                "result = await detector.detect(\"../data/samples/hinglish_meme.jpg\", \"cot\")\n",
                "display_result(result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reset to standard mode\n",
                "detector.set_vlm_prompt_mode(\"standard\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}